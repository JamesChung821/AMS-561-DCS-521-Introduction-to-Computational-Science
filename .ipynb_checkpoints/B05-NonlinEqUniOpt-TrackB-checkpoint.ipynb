{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Equations and Univeriate Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider the problem of finding the root for a function of the form $f(x) = 0$.\n",
    "\n",
    "For simple problems, we can solve it algebraically/symbolically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, a, b, c = sympy.symbols(\"x, a, b, c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b*x + c*x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.solve(a + b*x + c*x**2, x) # x is independant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.roots(a + b*x + c*x**2, x) # dictionary to represnt mutilplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.solve(a * sympy.cos(x) - b * sympy.sin(x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, symbolic computation is very limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22644/4147955481.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msympy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msympy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sympy.solve(sympy.sin(x)-x, x)\n",
    "except NotImplementedError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most problems of practical interests, we need to solve nonlinear equations numerically. This can be done using the `scipy.optimize.fsolve` function. It requires an initial guess: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fsolve(lambda x:np.sin(x)-x, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fsolve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a more complicated example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_c = 3.0\n",
    "def f(omega):\n",
    "    # a transcendental equation: resonance frequencies of a low-Q SQUID terminated microwave resonator\n",
    "    return np.tan(2*np.pi*omega) - omega_c/omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(figsize=(10,4))\n",
    "x = np.linspace(1.e-100, 3, 1000)\n",
    "y = f(x)\n",
    "mask = np.where(abs(y) > 50)\n",
    "x[mask] = y[mask] = np.NaN # get rid of vertical line when the function flip sign\n",
    "ax.plot(x, y)\n",
    "ax.plot([0, 3], [0, 0], 'k')\n",
    "ax.set_ylim(-5,5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may get different solutions from different starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fsolve(f, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fsolve(f, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fsolve(f, 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `fsolve` also works for multivariate functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return [x[1] - x[0]**3 - 2 * x[0]**2 + 1, x[1] + x[0]**2 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fsolve(f, np.array([1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisection method for univariate functions\n",
    "\n",
    "For univariate functions, a simple (but inefficient and  method for solving nonlinear equations is the bisection method, as illustrated below.\n",
    "\n",
    "We are seeking a solution to $f(x)=0$ and are told that the solution lies in the interval $[a,b]$. \n",
    "1. Evaluate the function at the end points ($a$ and $b$)\n",
    "2. Evaluate the function at the mid-point ($m=(a+b)/2$).  \n",
    "3. If the sign of $f(a)$ is the same as that of $f(m)$ it means the root is in the right half of the interval, so set $a=m$. Otherwise, the root must be in the left half, so set $b=m$.\n",
    "4. Repeat steps 2 and 3 until $b-a$ is sufficiently small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define a function, desired tolerance and starting interval [a, b]\n",
    "f = lambda x: np.exp(x) - 2\n",
    "tol = 0.1\n",
    "a, b = -2, 2\n",
    "x = np.linspace(-2.1, 2.1, 1000)\n",
    "\n",
    "# graph the function f\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "ax.plot(x, f(x), lw=1.5)\n",
    "ax.axhline(0, ls=':', color='k')\n",
    "ax.set_xticks([-2, -1, 0, 1, 2])\n",
    "ax.set_xlabel(r'$x$', fontsize=18)\n",
    "ax.set_ylabel(r'$f(x)$', fontsize=18)\n",
    "\n",
    "# find the root using the bisection method and visualize\n",
    "# the steps in the method in the graph\n",
    "fa, fb = f(a), f(b)\n",
    "\n",
    "ax.plot(a, fa, 'ko')\n",
    "ax.plot(b, fb, 'ko')\n",
    "ax.text(a, fa + 0.5, r\"$a$\", ha='center', fontsize=18)\n",
    "ax.text(b, fb + 0.5, r\"$b$\", ha='center', fontsize=18)\n",
    "\n",
    "n = 1\n",
    "while b - a > tol:\n",
    "    m = a + (b - a)/2\n",
    "    fm = f(m)\n",
    "\n",
    "    ax.plot(m, fm, 'ko')\n",
    "    ax.text(m, fm - 0.5, r\"$m_%d$\" % n, ha='center')\n",
    "    n += 1\n",
    "    \n",
    "    if np.sign(fa) == np.sign(fm):\n",
    "        a, fa = m, fm\n",
    "    else:\n",
    "        b, fb = m, fm\n",
    "\n",
    "ax.plot(m, fm, 'r*', markersize=10)\n",
    "ax.annotate(\"Root approximately at %.3f\" % m,\n",
    "            fontsize=14, family=\"serif\",\n",
    "            xy=(a, fm), xycoords='data',\n",
    "            xytext=(-150, +50), textcoords='offset points', \n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3, rad=-.5\"))\n",
    "\n",
    "ax.set_title(\"Bisection method in action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton's Method\n",
    "\n",
    "A more sophisticated method is Newton's method, in which\n",
    "$$x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}.$$\n",
    "<img src=\"https://www.ams.sunysb.edu/~jiao/teaching/ams561/images/newtons.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function, desired tolerance and starting point xk\n",
    "tol = 0.01\n",
    "xk = 2\n",
    "\n",
    "s_x = sympy.symbols(\"x\")\n",
    "s_f = sympy.exp(s_x) - 2\n",
    "\n",
    "f = lambda x: sympy.lambdify(s_x, s_f, 'numpy')(x)\n",
    "fp = lambda x: sympy.lambdify(s_x, sympy.diff(s_f, s_x), 'numpy')(x)\n",
    "\n",
    "x = np.linspace(-1, 2.1, 1000)\n",
    "\n",
    "# setup a graph for visualizing the root finding steps\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,4))\n",
    "\n",
    "ax.plot(x, f(x))\n",
    "ax.axhline(0, ls=':', color='k')\n",
    "\n",
    "# repeat Newton's method until convergence to the desired tolerance has been reached\n",
    "n = 0\n",
    "while f(xk) > tol:\n",
    "    xk_new = xk - f(xk) / fp(xk)\n",
    "\n",
    "    ax.plot([xk, xk], [0, f(xk)], color='k', ls=':')\n",
    "    ax.plot(xk, f(xk), 'ko')\n",
    "    ax.text(xk, -.5, r'$x_%d$' % n, ha='center')\n",
    "    ax.plot([xk, xk_new], [f(xk), 0], 'k-')\n",
    "\n",
    "    xk = xk_new\n",
    "    n += 1\n",
    "\n",
    "ax.plot(xk, f(xk), 'r*', markersize=15)\n",
    "ax.annotate(\"Root approximately at %.3f\" % xk,\n",
    "            fontsize=14, family=\"serif\",\n",
    "            xy=(xk, f(xk)), xycoords='data',\n",
    "            xytext=(-150, +50), textcoords='offset points', \n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3, rad=-.5\"))\n",
    "\n",
    "ax.set_title(\"Newton's method in action\")\n",
    "ax.set_xticks([-1, 0, 1, 2])\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most practical methods are some variate of Newton's method or quasi-Newton methods, such as the secant method.\n",
    "\n",
    "The secant method can be interpreted as using a finite difference approximation to estimate the derivative in Newton's method. Similar to the bisection method, the secant method uses two data points to determine a third one at each step. However, it uses not only the signs but also the values to draw a secant line through two points.\n",
    "<img src=\"https://www.ams.sunysb.edu/~jiao/teaching/ams561/images/secant.png\" width=\"400\">\n",
    "\n",
    "The slope of the scant is given by\n",
    "$$s_k = \\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}.$$\n",
    "The intersection of the secant with the $x$ axis is then\n",
    "$$x_{k+1} = x_k - \\frac{f(x_k)}{s_k} = x_k + \\frac{x_k-x_{k-1}}{f(x_{k-1}) / f(x_k) - 1}.$$\n",
    "\n",
    "We will leave this as an exercise in the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Optimization\n",
    "\n",
    "The *optimization* problem is to find maxima and minima of an *objective function*. Optimization is often referred to as *minimization*, because maximization can be formulated as minimizing its negative value. \n",
    "\n",
    "Optimization is closely related to root finding: because at the minima the slope (or first derivative) of the curve is zero for smooth functions. In general, optimization algorithms only finds local extrema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at how to find the minima of a simple function of a single variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    ''' The target function '''\n",
    "    return x**4 + 4*x**3 + (x-2)**2\n",
    "\n",
    "def dfdx(x):\n",
    "    ''' The slope or first derivative of f'''\n",
    "    return 4*x**3 + 12*x**2 + 2*(x-2)\n",
    "\n",
    "def d2fdx2(x):\n",
    "    ''' The curvature or second derivative of f'''\n",
    "    return 12*x**2 + 24*x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots()\n",
    "x = np.linspace(-3.2, 1.2, 100)\n",
    "ax.axhline(0)\n",
    "ax.plot(x, f(x), \"-b\", label=\"f\")\n",
    "ax.axvline(-0.796635786203095, linestyle=\"-.\")\n",
    "ax.axvline( 0.469617434058037, linestyle=\"-.\")\n",
    "ax.axvline(-2.67298164785494, linestyle=\"-.\")\n",
    "ax.plot(x, dfdx(x), \"-g\", label=\"df/dx\")\n",
    "#ax.plot(x, d2fdx2(x), \"-r\", label=\"d2f/dx2\")\n",
    "ax.legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a minimum the value of the function must increase if we move left or right --- i.e., \n",
    "\n",
    "* The minima are at *critical points* where the slope of the curve, or its first derivative, is zero.\n",
    "* There must be positive curvature (or the second derivative $\\frac{d^2f}{dx^2} > 0$).\n",
    "\n",
    "At a maximimum, the slope again must be zero, but there must be negative curvature (since the function must decrease if we move left or right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple problems, like the above, this can be solved analytically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are solving for an extremum or critical point by solving $\\frac{df}{dx}=0$ we can look at the second derivative to see what sort of critical point we have found.\n",
    "* $\\frac{d^2f}{dx^2}<0 \\ \\ \\implies \\ \\ $ maximum\n",
    "* $\\frac{d^2f}{dx^2}=0 \\ \\ \\implies \\ \\ $ inflection\n",
    "* $\\frac{d^2f}{dx^2}>0 \\ \\ \\implies \\ \\ $ minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff(x):\n",
    "    return x**5/5 - 4*x**3/3\n",
    "\n",
    "def dff(x):\n",
    "    return x**2*(x-2)*(x+2)\n",
    "\n",
    "def d2ff(x):\n",
    "    return 4*x**3 - 8*x\n",
    "\n",
    "fig, ax  = plt.subplots()\n",
    "ax.axhline(0)\n",
    "x = np.linspace(-2.5, 2.5, 100)\n",
    "ax.plot(x, ff(x), \"-b\", label=\"f\")\n",
    "ax.plot(x, dff(x), \"-g\", label=\"df/dx\")\n",
    "#ax.plot(x, d2ff(x), \"-r\", label=\"d2f/dx2\")\n",
    "ax.annotate('maximum',xy=(-2.2, 4.8))\n",
    "ax.annotate('inflection',xy=(-0.4, 0.5))\n",
    "ax.annotate('minimum',xy=(1.6, -5.0))\n",
    "\n",
    "ax.legend(loc=\"upper center\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sympy.Symbol(\"x\")\n",
    "objfunc = x**4 + 4*x**3 + (x-2)**2; objfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objfunc.diff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sols = sympy.solve(objfunc.diff(x), x); sols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sols[0].evalf(chop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sols[1].evalf(chop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sols[2].evalf(chop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objfunc.diff(x, 2).evalf(subs={x:sols[0]}, chop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objfunc.diff(x, 2).evalf(subs={x:sols[1]}, chop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objfunc.diff(x, 2).evalf(subs={x:sols[2]}, chop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Numerical solution\n",
    "\n",
    "Since most problems cannot be solved symbolically we must usually use numerical computing.\n",
    "\n",
    "We can use various functions in `scipy.optimize` to find a minimum (or more precisely, to find a critical point).\n",
    "\n",
    "For univariate problems, the main function is `scipy.optimize.fminbound`, which finds the minimum within an interval.\n",
    "\n",
    "Limiting the interval searched for a minimum is usually very important\n",
    "* many functions behave badly outside a certain range\n",
    "* your problem usually dictates that you want solutions only within a certain physically meaningful range\n",
    "* especially in many dimensions optimization is hard and the more you tell the optimizer the greater your chance of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize.fminbound?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize.fminbound(f, -4, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize.fminbound(f, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negf(x):\n",
    "    return -f(x)\n",
    "optimize.fminbound(negf, -2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could use `scipy.optimize.minimize_scalar` for automatic bracketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = optimize.minimize_scalar(f); x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, automatic bracketing is not fool proof. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(r):\n",
    "    return 2 * np.pi * r**2 + 2 / r\n",
    "\n",
    "r = np.linspace(1.e-20, 2, 100)\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "ax.plot(r, f(r), lw=2, color='b')\n",
    "ax.set_title(r\"$f(r) = 2\\pi r^2+2/r$\", fontsize=18)\n",
    "ax.set_xlabel(r\"$r$\", fontsize=18)\n",
    "ax.set_xticks([0, 0.5, 1, 1.5, 2])\n",
    "ax.set_ylim(0, 30)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    x = optimize.minimize_scalar(f)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = optimize.minimize_scalar(f, bracket=(0.1, 4)); output.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Material: Methods for Univariate Optimization\n",
    "\n",
    "### Golden section search\n",
    "\n",
    "The golden-section search for minimization is analogous to the bisection method for root finding. It starts with an interval with opposite signs of slopes, and repeatedly shrinks the interval until the length of interval is within some tolerance.\n",
    "\n",
    "<img src=\"https://www.ams.sunysb.edu/~jiao/teaching/ams561/images/golden_section.png\" width=\"400\">\n",
    "<img src=\"https://www.ams.sunysb.edu/~jiao/teaching/ams561/images/golden_section_shrink.png\" width=\"280\">\n",
    "\n",
    "The following code implements the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def golden_section(f, a, b, tol):\n",
    "    '''\n",
    "    finds a minimum of f(x) within the interval [a,b] using the\n",
    "    golden-section search. It assumes f has negative slope\n",
    "    at a and positive slope at b.\n",
    "    '''\n",
    "\n",
    "    tau = (np.sqrt(5) - 1) / 2 # golden ratio\n",
    "    x1 = a + (1 - tau) * (b - a)\n",
    "    x2 = a + tau * (b - a)\n",
    "    f1, f2 = f(x1), f(x2)\n",
    "\n",
    "    k = 0\n",
    "    while b-a > tol:\n",
    "        if f1 > f2:\n",
    "            a = x1\n",
    "            x1 = x2\n",
    "            f1 = f2\n",
    "            x2 = a + tau * (b-a)\n",
    "            f2 = f(x2)\n",
    "        else:\n",
    "            b = x2\n",
    "            x2 = x1\n",
    "            f2 = f1\n",
    "            x1 = a + (1 - tau) * (b-a)\n",
    "            f1 = f(x1)\n",
    "\n",
    "        k = k + 1\n",
    "\n",
    "    x = (a + b) / 2;\n",
    "\n",
    "    return x, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, k = golden_section(f, 0.1, 4, 1.e-12); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Successive Parabolic Interpolation\n",
    "\n",
    "Successive parabolic interpolation for minimization is analogous to the secant method to root finding. It uses three points to construct a quadratic interpolation.\n",
    "\n",
    "<img src=\"https://www.ams.sunysb.edu/~jiao/teaching/ams561/images/parabolic_interp.png\" width=\"400\">\n",
    "\n",
    "The method converges faster than golden-section search.\n",
    "\n",
    "The following code illustrates the idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spi(f, a, b, tol):\n",
    "    'SPI minimizes f(x) using successive parabolic interpolation.'\n",
    "\n",
    "    maxiter = 100\n",
    "\n",
    "    xs = np.array([a, (a+b)/2, b])\n",
    "    fx = f(xs)\n",
    "\n",
    "    for k in range(1, maxiter+1):\n",
    "        # For simplicity, we use numpy.polyfit for constructing quadratic polynomial\n",
    "        p = np.polyfit(xs, fx, 2)\n",
    "        x = -0.5*p[1] / p[0]  # minimum of quadratic a*x**2 + b*x + c is at x=-b/2a\n",
    "\n",
    "        xs = np.array([xs[1], xs[2], x])\n",
    "        fx = np.array([fx[1], fx[2], f(x)])\n",
    "\n",
    "        if abs(xs[2]-xs[1]) < tol * abs(xs[1]):\n",
    "            break\n",
    "\n",
    "    x = xs[2]\n",
    "    return x, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.polyfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, k = spi(f, 0.1, 4, 1.e-6); x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Method for Efficiency and Robustness\n",
    " \n",
    "Most robust 1-D optimization methods combine the golden-section search and successive parabolic interpolation. This method was due to Richard Brent, and hence it is sometimes referred to as Brent's method. In SciPy, it can be accessed through `brent` or `minimize_scalar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize.brent(f, brack=(0.1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = optimize.minimize_scalar(f, bracket=(0.1, 4), method='Brent'); x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Chapter 5 of Numerical Python book for nonlinear equations\n",
    "* Chapter 6 of Numerical Python book on optimization\n",
    "* SciPy optimization package: http://scipy-lectures.github.com/advanced/mathematical_optimization/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "Adapted from J.R. Johansson's Scientific Python Lectures available at [http://github.com/jrjohansson/scientific-python-lectures](http://github.com/jrjohansson/scientific-python-lectures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
