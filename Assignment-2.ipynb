{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing data in files using basic Python and the Python CSV module\n",
    "\n",
    "For this homework, unless told otherwise, **please don't** use Python modules such as Pandas --- the goal is to practice using basic Python and data structures.  We will start using these other modules later in the course.\n",
    "\n",
    "## 1.  Computing and displaying the frequency of words and letters in text\n",
    "\n",
    "This question is intended for your practice using dictionaries and learning about `collections.defaultdict`.\n",
    "\n",
    "We will again use \"allswell.txt\" to provide the data.   \n",
    "\n",
    "\n",
    "### 1.a Write a function that \n",
    "\n",
    "1. takes a string as an argument, \n",
    "2. replaces with a space any character that is not a lowercase letter, and \n",
    "3. returns a new string\n",
    "\n",
    "Test it on the string \n",
    "```\n",
    "'once more unto the breach, dear friends, once more;'\n",
    "``` \n",
    "\n",
    "It should return \n",
    "\n",
    "``` \n",
    "'once more unto the breach  dear friends  once more '\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Count the number of times each word and letter character appears in `allswell.txt` \n",
    "\n",
    "\n",
    "We did something like this in class, but now we want to be more intelligent about how we distinguish words and handle punctuation and mixed case.\n",
    "* when you read a line of text immediately convert it to lowercase so that \n",
    "  1. you don't end up with words/letters that differ just by case, and\n",
    "  2. when comparing characters you don't have to worry about their case\n",
    "* before splitting into words use the function you just wrote to remove characaters that are not letters or space \n",
    "\n",
    "Print out the number of distinct words and characters.\n",
    "\n",
    "[Aside: You could try to use the `collections.defaultdict` but using the usual python dictionary is OK too.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Make a list of the word counts (i.e., how many times each word appears), sort it in decreasing order and plot the data using a bar chart\n",
    "\n",
    "This is an example of a long-tailed distribution - there are many words that are individually infrequently used, but collectively they are responsible for a lot of the words used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those of you wanting a slightly harder problem, print out the words in order of decreasing frequency. If you don't want to do it, then read my solutions and insert comments on how they work.\n",
    "\n",
    "I give two solutions below assuming the dictionary you made containing the word counts is called `word_counts`, but there are several ways of doing it.  The second approach is rather advanced - look in the documentation for `sorted` (https://docs.python.org/3/library/functions.html#sorted) to see if you can understand it - I don't expect everyone should at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "count_to_words = collections.defaultdict(list)\n",
    "for word in word_counts:\n",
    "    count_to_words[word_counts[word]].append(word)\n",
    "\n",
    "for count in sorted(count_to_words,reverse=True):\n",
    "    print(\"% 4d\" % count, count_to_words[count])\n",
    "\n",
    "# Uncomment this to run the second solution\n",
    "#for word in sorted(word_counts, key=word_counts.__getitem__, reverse=True):\n",
    "#    print(\"%10s %d\" % (word,word_counts[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Using Python to analyze a CSV file\n",
    "\n",
    "Again, **please do this section with basic Python instead of an existing Python module.**\n",
    "\n",
    "The data we are using is (an older version) taken from https://catalog.data.gov/dataset/demographic-statistics-by-zip-code.\n",
    "\n",
    "A CSV (comma-separated values) file is a table written out with one row per line.  Within each line, values are separated by commas.  Often the first row (and perhaps the first column) are interpreted as headers or labels.\n",
    "\n",
    "Download from the Blackboard assignment page the file `'Demographic_Statistics_By_Zip_Code.csv'` --- have a look at it using either a text editor (or if you prefer you could try importing it into a spread sheet program like Excel).\n",
    "\n",
    "The headings for each column of data in the file (i.e., the first line in the file) are\n",
    "\n",
    "```\n",
    "JURISDICTION NAME,COUNT PARTICIPANTS,COUNT FEMALE,PERCENT FEMALE,COUNT MALE,PERCENT MALE,COUNT GENDER UNKNOWN,PERCENT GENDER UNKNOWN,COUNT GENDER TOTAL,PERCENT GENDER TOTAL,COUNT PACIFIC ISLANDER,PERCENT PACIFIC ISLANDER,COUNT HISPANIC LATINO,PERCENT HISPANIC LATINO,COUNT AMERICAN INDIAN,PERCENT AMERICAN INDIAN,COUNT ASIAN NON HISPANIC,PERCENT ASIAN NON HISPANIC,COUNT WHITE NON HISPANIC,PERCENT WHITE NON HISPANIC,COUNT BLACK NON HISPANIC,PERCENT BLACK NON HISPANIC,COUNT OTHER ETHNICITY,PERCENT OTHER ETHNICITY,COUNT ETHNICITY UNKNOWN,PERCENT ETHNICITY UNKNOWN,COUNT ETHNICITY TOTAL,PERCENT ETHNICITY TOTAL,COUNT PERMANENT RESIDENT ALIEN,PERCENT PERMANENT RESIDENT ALIEN,COUNT US CITIZEN,PERCENT US CITIZEN,COUNT OTHER CITIZEN STATUS,PERCENT OTHER CITIZEN STATUS,COUNT CITIZEN STATUS UNKNOWN,PERCENT CITIZEN STATUS UNKNOWN,COUNT CITIZEN STATUS TOTAL,PERCENT CITIZEN STATUS TOTAL,COUNT RECEIVES PUBLIC ASSISTANCE,PERCENT RECEIVES PUBLIC ASSISTANCE,COUNT NRECEIVES PUBLIC ASSISTANCE,PERCENT NRECEIVES PUBLIC ASSISTANCE,COUNT PUBLIC ASSISTANCE UNKNOWN,PERCENT PUBLIC ASSISTANCE UNKNOWN,COUNT PUBLIC ASSISTANCE TOTAL,PERCENT PUBLIC ASSISTANCE TOTAL\n",
    "```\n",
    "\n",
    "### 2.a.  Write a function to extract the column of data from the file corresponding to a given heading\n",
    "\n",
    "E.g., given `'JURISDICTION NAME`` return a list containing all of the zip codes\n",
    "\n",
    "* Raise a `ValueError` exception if the heading is not found\n",
    "\n",
    "* Since in this file all of the data (except for headings) are numbers, please return a list of floats (not strings).\n",
    "\n",
    "Test it on `'JURISDICTION NAME'` and `'COUNT PARTICIPANTS'` as well as on a heading that does not exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b.  Now you are armed to explore the data!\n",
    "\n",
    "Which zip code has the most males?\n",
    "\n",
    "Which zip code has the most permanent resident aliens?\n",
    "\n",
    "What are the max, min, mean, median, mode and variance of the `'COUNT AMERICAN INDIAN'`? Hint: remember the statistics module?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c  Making scatter plots\n",
    "\n",
    "We can visually explore (non-quantitatively) correlations between two quantities by making a scatter plot which takes two vector of data (e,g, x and y) plots each pair of values as a point (don't connect the points with lines).\n",
    "\n",
    "Let's look to see what's correlated with the number of people on public assistance.\n",
    "\n",
    "First, we might expect that the number of people on assistance would increase with the total number of people.  So, to test this expectation, please make a scatter plot of `'COUNT RECEIVES PUBLIC ASSISTANCE'` (y-axis) against `'COUNT PARTICIPANTS'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visually supports the expected correlation.\n",
    "\n",
    "Make a figure with 4 subplots showing the correlation of 'COUNT RECEIVES PUBLIC ASSISTANCE' with each of 'PERCENT HISPANIC LATINO', 'PERCENT BLACK NON HISPANIC', 'PERCENT US CITIZEN' and 'PERCENT ASIAN NON HISPANIC'.  Don't forget to label the axes, make sure the plots don't overlap (hint: read about tight layout), and that the text is readable (hint: font size and perhaps a strategic new line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Using Python's CSV module to analyze a CSV file\n",
    "\n",
    "Please use the Python CSV module to complete this section.\n",
    "\n",
    "* https://docs.python.org/3/library/csv.html\n",
    "\n",
    "### 3.a.  Use Python's CSV module to print out each record in the data file, numbering each line\n",
    "\n",
    "E.g., the first few lines of your output should look something like\n",
    "```\n",
    "   0 ['JURISDICTION NAME', 'COUNT PARTICIPANTS', 'COUNT FEMALE', etc.]\n",
    "   1 ['10001', '44', '22', '0.5', '22', '0.5', '0', '0', '44', etc.]\n",
    "   2 ['10002', '35', '19', '0.54', '16', '0.46', '0', '0', etc.]\n",
    "   etc.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, you should now see how to use the CSV module to process a CSV file.  Each line immediately becomes a list that you can easily process.  As the documentation indicates, the CSV module can handle many/most of the weird different formats called CSV.  Thus, you should prefer using it to writing your own code (as we did above for Python practice).\n",
    "\n",
    "### 3.b.  Let's write a CSV file using the Python CSV module\n",
    "\n",
    "Write out a new CSV file called `'mydata.csv'` containing just the columns 'JURISDICTION NAME', 'COUNT PARTICIPANTS', 'COUNT FEMALE', 'COUNT MALE', and 'COUNT RECEIVES PUBLIC ASSISTANCE', and only for the zip codes 10024, 10025, 10026, and 10027.\n",
    "\n",
    "* Note: you should close your file once you are finished writing so that all of the output is flushed to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c.  Print the new CSV file you created just as you did the full file in 3.a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
