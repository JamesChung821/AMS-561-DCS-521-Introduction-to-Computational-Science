{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical computation\n",
    "\n",
    "1. Representation of integers in Python and NumPy\n",
    "   - Maximum/minimum values, overflow\n",
    "1. Concepts of\n",
    "   - Absolute error\n",
    "   - Relative error\n",
    "   - Precision and representation error\n",
    "   - Accuracy\n",
    "2. Representation of floating point numbers in Python and NumPy\n",
    "   - Maximum/minimum values, machine precision, overflow and underflow\n",
    "   - Representation error\n",
    "   - Roundoff error\n",
    "   - Commutative, associative and distributive properties\n",
    "   - Comparison of floating point values\n",
    "   - Cancellation error\n",
    "   - Summation example\n",
    "   - Quadratic equation example\n",
    "   - Extended precision\n",
    "1. Classic very detailed reference about floating point numbers https://www.itu.dk/~sestoft/bachelor/IEEE754_article.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integers\n",
    "\n",
    "### Division operation\n",
    "\n",
    "In Python3, integer division is not closed, unless use `//` operator.  I.e., if you use '/' to divide two integers the result is always a floating point number even if the result is whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python3:    4/2 2.0\n",
      "Python3:    3/2 = 1.5     3//2 = 1    1//2 = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Python3:    4/2\", 4/2)\n",
    "print(\"Python3:    3/2 =\", 3/2, \"    3//2 =\", 3//2, \"   1//2 =\",1//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NumPy behaves the same way*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5]\n",
      "[0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "print(a.dtype)\n",
    "print(a)\n",
    "print(a/2)\n",
    "print(a/np.full(10,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allowed values of integers\n",
    "\n",
    "Native Python3 integers can be arbitrarily large (positive or negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " m       2**m             2**m in binary format\n",
      "--    ----------     -------------------------------------\n",
      " 0             1                                         1\n",
      " 1             2                                        10\n",
      " 2             4                                       100\n",
      " 3             8                                      1000\n",
      " 4            16                                     10000\n",
      " 5            32                                    100000\n",
      " 6            64                                   1000000\n",
      " 7           128                                  10000000\n",
      " 8           256                                 100000000\n",
      " 9           512                                1000000000\n",
      "10          1024                               10000000000\n",
      "11          2048                              100000000000\n",
      "12          4096                             1000000000000\n",
      "13          8192                            10000000000000\n",
      "14         16384                           100000000000000\n",
      "15         32768                          1000000000000000\n",
      "16         65536                         10000000000000000\n",
      "17        131072                        100000000000000000\n",
      "18        262144                       1000000000000000000\n",
      "19        524288                      10000000000000000000\n",
      "20       1048576                     100000000000000000000\n",
      "21       2097152                    1000000000000000000000\n",
      "22       4194304                   10000000000000000000000\n",
      "23       8388608                  100000000000000000000000\n",
      "24      16777216                 1000000000000000000000000\n",
      "25      33554432                10000000000000000000000000\n",
      "26      67108864               100000000000000000000000000\n",
      "27     134217728              1000000000000000000000000000\n",
      "28     268435456             10000000000000000000000000000\n",
      "29     536870912            100000000000000000000000000000\n",
      "30    1073741824           1000000000000000000000000000000\n",
      "31    2147483648          10000000000000000000000000000000\n",
      "32    4294967296         100000000000000000000000000000000\n",
      "33    8589934592        1000000000000000000000000000000000\n",
      "34   17179869184       10000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(\" m       2**m             2**m in binary format\")\n",
    "print(\"--    ----------     -------------------------------------\")\n",
    "\n",
    "for iteration in range(35):\n",
    "    print(\"{0:2d}  {1:12d}  {1:40b}\".format(iteration,i))\n",
    "    i*=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, NumPy has integers with a fixed size for compact storage and efficient computing (since this is what the computer hardware actually uses)\n",
    "\n",
    "E.g., a 32-bit integer is a sequence of 32 bits (4 bytes) using two's complement representation (https://en.wikipedia.org/wiki/Two%27s_complement)\n",
    "\n",
    "```\n",
    " [bit31, bit30, bit29, bit28, ..., bit2, bit1, bit0]\n",
    " ```\n",
    "\n",
    "$i = - b_{31}*2^{31} +  b_{30}*2^{30} +  b_{29}*2^{29}+  b_{28}*2^{28} + \\cdots + b_{2}*2^{2} + b_{1}*2^{1} + b_{0}*2^0 $\n",
    "\n",
    "Most modern computers support in hardware 8-bit, 16-bit, 32-bit, and 64-bit integers (with and without signs)\n",
    "\n",
    "The default integer in NumPy is 64-bit.\n",
    "\n",
    "If you are curious, or if you ever need to do it by hand:\n",
    "* Computing the binary representation of a positive number is straightforward.  In decreasing order, subtract powers of two less than the value.  For example, `265`.  The largest power of 2 less than 265 is $2^8=256$.  Subtracting 256 leaves $9$, which you can see is `8+1 = 2^3 + 2^0`, so the 32-bit binary representation of `265` is `00000000000000000000000100001001`.\n",
    "* For a negative integer $-i$ the lower 31 bits are computed from $2^{31}-i$ and the 32nd bit is set.  So armed with the binary representation of +265 we can compute the two's-complement binary representation of -265 by first computing (in binary) $2^{31}-265$.\n",
    "\n",
    "```\n",
    "  10000000000000000000000000000000\n",
    "- 00000000000000000000000010001001\n",
    "= 01111111111111111111111101110111\n",
    "```\n",
    "\n",
    "and then seting the upper bit to obtain `11111111111111111111111011110111`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** In two's-complement 32-bit format, what are the binary representations of \n",
    "* 3\n",
    "* -3\n",
    "\n",
    "If you want to check your answer look [here](https://www.exploringbinary.com/twos-complement-converter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "-11\n"
     ]
    }
   ],
   "source": [
    "# Aside: Python can print binary representations of integers but does not internally use the\n",
    "# two's-complement representation and so negative numbers appear just with a minus sign\n",
    "print(\"{:b}\".format(3))\n",
    "print(\"{:b}\".format(-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function to convert an integer into a string containing its binary 32-bit two's-complement representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2147483648 10000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "def b(i, nbits=32):\n",
    "    ''' Returns bit-string representation of a 32-bit two's-complement integer '''\n",
    "    if i<-2**(nbits-1) or i>=2**(nbits-1):\n",
    "        raise(ValueError)\n",
    "    s = \"0\"\n",
    "    if i<0:\n",
    "        s = \"1\"\n",
    "        i += 2**(nbits-1)\n",
    "    for q in range(nbits-2,-1,-1):\n",
    "        s += [\"0\",\"1\"][(i&(1<<q))>>q]\n",
    "    return s\n",
    "\n",
    "print(-2147483648, b(-2147483648)) # The most negative integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          3 00000000000000000000000000000011\n",
      "         -3 11111111111111111111111111111101\n"
     ]
    }
   ],
   "source": [
    "# Test it on some integers from numpy\n",
    "import numpy as np\n",
    "i = np.array([3],np.int32)\n",
    "print(\"{0:11d} {1}\".format(i[0],b(i[0])))\n",
    "i[0] = -3\n",
    "print(\"{0:11d} {1}\".format(i[0],b(i[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fixed width of NumPy integers means they cannot be arbitrarily large. The largest positive value you can put in a 32-bit signed integer must fit into 31 bits which is\n",
    "\n",
    "$2^{31}-1$ = 2147483647\n",
    "\n",
    "And the largest magnitude negative value is \n",
    "$-2^{31}$ = -2147483648\n",
    "\n",
    "For the default 64-bit integers the limits are $2^{63}-1$ = 9223372036854775807 and $-2^{63}$=-9223372036854775808\n",
    "\n",
    "**Exercise:** Explain the following behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2147483647 01111111111111111111111111111111\n",
      "-2147483648 10000000000000000000000000000000\n",
      "\n",
      "-2147483648 10000000000000000000000000000000\n",
      " 2147483647 01111111111111111111111111111111\n",
      "         -1 11111111111111111111111111111111\n"
     ]
    }
   ],
   "source": [
    "# Unexpected things can happen when you \"overflow\" a fixed-size integer\n",
    "\n",
    "i = np.array([2**31-1],np.int32)\n",
    "print(\"{0:11d} {1}\".format(i[0],b(i[0])))\n",
    "i += 1\n",
    "print(\"{0:11d} {1}\".format(i[0],b(i[0])))\n",
    "print()\n",
    "i = np.array([-2**31],np.int32)\n",
    "print(\"{0:11d} {1}\".format(i[0],b(i[0])))\n",
    "i -= 1\n",
    "print(\"{0:11d} {1}\".format(i[0],b(i[0])))\n",
    "print(\"{0:11d} {1}\".format(-1,b(-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0            1   00000000000000000000000000000001\n",
      " 1            2   00000000000000000000000000000010\n",
      " 2            4   00000000000000000000000000000100\n",
      " 3            8   00000000000000000000000000001000\n",
      " 4           16   00000000000000000000000000010000\n",
      " 5           32   00000000000000000000000000100000\n",
      " 6           64   00000000000000000000000001000000\n",
      " 7          128   00000000000000000000000010000000\n",
      " 8          256   00000000000000000000000100000000\n",
      " 9          512   00000000000000000000001000000000\n",
      "10         1024   00000000000000000000010000000000\n",
      "11         2048   00000000000000000000100000000000\n",
      "12         4096   00000000000000000001000000000000\n",
      "13         8192   00000000000000000010000000000000\n",
      "14        16384   00000000000000000100000000000000\n",
      "15        32768   00000000000000001000000000000000\n",
      "16        65536   00000000000000010000000000000000\n",
      "17       131072   00000000000000100000000000000000\n",
      "18       262144   00000000000001000000000000000000\n",
      "19       524288   00000000000010000000000000000000\n",
      "20      1048576   00000000000100000000000000000000\n",
      "21      2097152   00000000001000000000000000000000\n",
      "22      4194304   00000000010000000000000000000000\n",
      "23      8388608   00000000100000000000000000000000\n",
      "24     16777216   00000001000000000000000000000000\n",
      "25     33554432   00000010000000000000000000000000\n",
      "26     67108864   00000100000000000000000000000000\n",
      "27    134217728   00001000000000000000000000000000\n",
      "28    268435456   00010000000000000000000000000000\n",
      "29    536870912   00100000000000000000000000000000\n",
      "30   1073741824   01000000000000000000000000000000\n",
      "31  -2147483648   10000000000000000000000000000000\n",
      "32            0   00000000000000000000000000000000\n",
      "33            0   00000000000000000000000000000000\n",
      "34            0   00000000000000000000000000000000\n",
      "35            0   00000000000000000000000000000000\n",
      "36            0   00000000000000000000000000000000\n",
      "37            0   00000000000000000000000000000000\n",
      "38            0   00000000000000000000000000000000\n",
      "39            0   00000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Explore increasing powers of 2\n",
    "i = np.array([1],np.int32)\n",
    "for iteration in range(40):\n",
    "    print(\"{0:2d}  {1:11d}   {2}\".format(iteration,i[0],b(i[0])))\n",
    "    i *= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:** *these issues only affect very large integers in NumPy (or other programming languages including Python2) and most of the time things will behave as you expect.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute error, relative error, significant digits, precision, and accuracy\n",
    "\n",
    "These are central concepts to numerical computation\n",
    "\n",
    "**Absolute error** is the magnitude of the error between an approximate result and the exact one $\\epsilon_{\\mathrm{abs}} = |x_\\mathrm{exact} - x_{\\mathrm{approx}}|$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.000000000000001\n",
      "8.881784197001252e-16\n"
     ]
    }
   ],
   "source": [
    "x = (1.0/(1.0/7.0**0.5)**3)**(2/3) #  exact answer is 7\n",
    "xexact = 7\n",
    "print(x)\n",
    "abserr = abs(x-7)\n",
    "print(abserr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While absolute error is very important, it requires that we have some understanding about how big an error is bad.  \n",
    "\n",
    "For instance, an error of a million would be a lot if counting the population of a town, but would likely be regarded as small if measuring the distance to the sun in meters (149,597,870,700m).\n",
    "\n",
    "**Relative error** can be defined as ratio of the absolute error to the exact result \n",
    "\n",
    "$$ \\epsilon_{\\mathrm{rel}} = |x_\\mathrm{exact} - x_{\\mathrm{approx}}| / |x_\\mathrm{exact}| $$\n",
    "\n",
    "but other definitions are also useful depending on the circumstance, e.g.,\n",
    "\n",
    "$$ \\epsilon_{\\mathrm{rel}} = |x_\\mathrm{exact} - x_{\\mathrm{approx}}| / \\mathrm{max}(|x_\\mathrm{exact}|,|x_\\mathrm{approx}|) $$\n",
    "\n",
    "$$ \\epsilon_{\\mathrm{rel}} = |x_\\mathrm{exact} - x_{\\mathrm{approx}}| / |x_\\mathrm{approx}| $$\n",
    "\n",
    "From the perspective of relative error we can see the above computation was quite accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2688263138573217e-16\n"
     ]
    }
   ],
   "source": [
    "relerr = abs(x-xexact)/xexact\n",
    "print(relerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Significant digits:** Relative error can also be interpreted as the number of significant figures or digits ($N$) in the value, where $N$ is computed as the largest integer such that \n",
    "\n",
    "$$ \\epsilon_{\\mathrm{rel}} < 0.5 * 10^{-N} $$\n",
    "\n",
    "or \n",
    "\n",
    "$$\n",
    "N \\approx \\mathrm{floor}( -\\log_{10} (2* \\epsilon_{\\mathrm{rel}}) ),\n",
    "$$\n",
    "\n",
    "assuming that $\\epsilon_{\\mathrm{rel}}> 0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "sigfig = int(-log10(2*relerr))\n",
    "print(sigfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Precision** is often stated as the number of digits (or relative error) used to store or compute a result. Sometimes this might be stated as relative error, or the absolute error (e.g., if fixed-point arithmetic is being used instead of floating point).\n",
    "\n",
    "For example, here is an approximation to $\\pi$\n",
    "```\n",
    "   piapprox = 3.1415243098283216\n",
    "```\n",
    "that has been specified with a precision of 17 digits.  We will see below that IEEE double-precision floating-point arithmetic has a precision of about 16 digits (and specifying a correctly rounded value can require a few more digits).\n",
    "\n",
    "Note: if we had specified more digits that they would have been discarded --- double-precision simply cannot hold any more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415243098283216\n",
      "3.1415243098283216\n"
     ]
    }
   ],
   "source": [
    "piapprox = 3.1415243098283216\n",
    "print(piapprox)\n",
    "piapprox = 3.1415243098283216217439821748972198\n",
    "print(piapprox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Representation error:** because of finite precision some values cannot be exactly represented --- this is usually not a problem but can lead to some unexpected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415243098283216\n",
      "0.20000000000000001\n"
     ]
    }
   ],
   "source": [
    "print(3.1415243098283217)  # focus on the last digit\n",
    "print(\"%.17f\" % 0.2)       # focus on the last digit --- running error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2246467991473532e-16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sin(math.pi)          # pi is not exactly representable, so sin(pi) cannot be exactly zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** is often stated as the number of signficant figures in a value comparing to the exact or true value. Sometimes relative or absolute error might be used.\n",
    "\n",
    "Clearly the attainable accuracy is limited by the precision of computation, but there may be other limits\n",
    "*  finite accuracy of values input into a calculation\n",
    "*  finite accuracy of an algorithm to compute something\n",
    "\n",
    "Looking at the above approximate value for $\\pi$ that was stated with a precision of 17 digits we can see that it is only accurate to a little more than 4 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx: 3.1415243098283216\n",
      " exact: 3.141592653589793 (i.e., the closest floating-point representation of pi)\n",
      "relerr: 2.1754494935355024e-05\n",
      "sigfig: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"approx:\", piapprox)\n",
    "print(\" exact:\", math.pi, \"(i.e., the closest floating-point representation of pi)\")\n",
    "pirelerr = abs(piapprox-math.pi)/math.pi\n",
    "print(\"relerr:\", pirelerr)\n",
    "N = int(-log10(2*pirelerr))\n",
    "print(\"sigfig:\", N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating point numbers \n",
    "\n",
    "Nearly all languages, including Python and NumPy, use the computer hardware suported IEEE 754 representation. \n",
    "* NumPy supports the most commonly used single precision (32-bit) and double precision (64-bit) floating-point numbers as `float32` and `float64`.\n",
    "* NumPy also supports the newer half precision (16 bits) as `float16`.\n",
    "\n",
    "E.g., in 64-bit (https://en.wikipedia.org/wiki/Double-precision_floating-point_format)\n",
    "\n",
    "$$(-1)^s \\times 1.m \\times 2^{e-1023}$$\n",
    "\n",
    "- 1 bit for sign ($s$)\n",
    "- 11 bits for exponent ($e$)\n",
    "  - In range -1024 to +1023 in binary, or $\\pm$308 in decimal.  Thus, numbers larger than circa $10^{308}$ will overflow, and numbers smaller than circa $10^{-308}$ will underflow (gradually due to denormalized representation)\n",
    "- 52 bits for mantissa ($m$) giving 53 bits of signifance \n",
    "  - 53 bits since we know for a non-zero number that the leading binary digit is 1 so we don't bother storing that\n",
    "  - $2^{-53} \\approx$ `1.11e-16`\n",
    "- Special values are reserved to represent\n",
    "  - Signed zero\n",
    "  - Overflow (number too in magnitude to represent) --- $\\pm \\infty$\n",
    "  - Not a number (result is not a valid number) --- `NaN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For native Python these limits and associated values can be found in `sys.float_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)\n",
      "\n",
      "maximum floating point number is 1.7976931348623157e+308\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.float_info)\n",
    "print()\n",
    "print(\"maximum floating point number is\", sys.float_info.max)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Or for NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for float64\n",
      "---------------------------------------------------------------\n",
      "precision =  15   resolution = 1.0000000000000001e-15\n",
      "machep =    -52   eps =        2.2204460492503131e-16\n",
      "negep =     -53   epsneg =     1.1102230246251565e-16\n",
      "minexp =  -1022   tiny =       2.2250738585072014e-308\n",
      "maxexp =   1024   max =        1.7976931348623157e+308\n",
      "nexp =       11   min =        -max\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_29548/891928311.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  print(np.finfo(np.float))\n"
     ]
    }
   ],
   "source": [
    "print(np.finfo(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e+308\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "# Illustrating what happens when you exceed the most postitive exponent --- overflow\n",
    "x = 10.0**308\n",
    "print(x)\n",
    "x *= 2.0\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7976931348623157e+308\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "# Illustrating what happens when you exceed the most postitive exponent and mantissa --- overflow\n",
    "import sys\n",
    "x = sys.float_info.max\n",
    "print(x)\n",
    "x = x*1.0000000000000002\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2345678901234568e-307\n",
      "1.2345678901234567e-308\n",
      "1.234567890123457e-309\n",
      "1.23456789012346e-310\n",
      "1.2345678901233e-311\n",
      "1.234567890124e-312\n",
      "1.2345678901e-313\n",
      "1.23456789e-314\n",
      "1.23456789e-315\n",
      "1.2345679e-316\n",
      "1.234568e-317\n",
      "1.234566e-318\n",
      "1.23457e-319\n",
      "1.2347e-320\n",
      "1.235e-321\n",
      "1.24e-322\n",
      "1.5e-323\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Illustrating what happens as you approach and exceed the most negative exponent (i.e., very small numbers) --- gradual underflow\n",
    "x = 1.23456789012345678e-307\n",
    "while x>0:\n",
    "    print(x)\n",
    "    x *= 0.1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine epsilon** (https://en.wikipedia.org/wiki/Machine_epsilon) is the smallest positive number such that \n",
    "\n",
    "$1 + \\epsilon \\ne 1$\n",
    "\n",
    "It is the **relative error** for floating point computation.\n",
    "\n",
    "For any real value $x$ (assuming no over/underflow) there exists a numerical representation $x^\\prime$ such that $|x-x^\\prime| < \\epsilon |x|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-60 8.673617379884035e-19 1.0\n",
      "-59 1.734723475976807e-18 1.0\n",
      "-58 3.469446951953614e-18 1.0\n",
      "-57 6.938893903907228e-18 1.0\n",
      "-56 1.3877787807814457e-17 1.0\n",
      "-55 2.7755575615628914e-17 1.0\n",
      "-54 5.551115123125783e-17 1.0\n",
      "-53 1.1102230246251565e-16 1.0\n",
      "-52 2.220446049250313e-16 1.0000000000000002\n",
      "\n",
      "2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "# Computing epsilon (normally would just look in sys.float_info)\n",
    "for n in range(-60,1):\n",
    "    epsilon = 2.0**n\n",
    "    print(n, epsilon, 1.0+epsilon)\n",
    "    if (1.0+epsilon) != 1.0:\n",
    "        break\n",
    "print()\n",
    "print(sys.float_info.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rounding error:** Is related to representation error already introduced above. While some numbers and floating computations can be, or can appear to be, exact, most suffer rounding error because the significand has only 53 bits, and the last bit must usually be rounded. \n",
    "\n",
    "This gives you 15-16 significant decimal figures.\n",
    "\n",
    "In IEEE 754 floating point arithmetic the default rounding mode is towards the closest exactly representable number.  Other rounding modes are available (e.g., round to zero, etc.) but are rarely needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.440892098500626e-16\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(0.3/0.1-3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IEEE standard requires that the result of addition, subtraction, multiplication, division, square root, remainder, and conversion between integer and floating-point be *correctly rounded*.  It is not possible to do this efficiently for transcendental functions (e.g., `exp`) but these days most math libraries do correctly round all values and offer slightly less accurate modes (errors in the last 1-3 bits) that are potentially much faster.\n",
    "\n",
    "More precisely, let $\\times = +, -, *, /, \\ldots$ in exact arithmetic and let $\\otimes$ be the corresponding floating-point operation. Assuming no under/overflow, IEEE 754 arithmetic guarantees that given two floating-point values $x$ and $y$ that $|(x*y) - (x\\otimes y)| < \\epsilon |x*y|$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point arithmetic is *commutative* but *not associative* and *not distributive*\n",
    "\n",
    "Commutative means $x \\otimes y = y\\otimes x$ and in floating point arithmetic this is true for $\\otimes=+$ or $\\otimes=*$.\n",
    "\n",
    "Associative means $(x \\otimes y) \\otimes z = x \\otimes (y \\otimes z)$ where sub-expressions within parentheses are evaluated first.\n",
    "\n",
    "Distributive means $x\\otimes(y + z) = x\\otimes y + x \\otimes z$ for $\\otimes = *, /$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "relative error in associative test 1.2315884211280873e-16\n",
      "False\n",
      "relative error in distributive test 1.3173314488952503e-16\n"
     ]
    }
   ],
   "source": [
    "x=239480912809.2930841092\n",
    "y=8309482109.193284092183018\n",
    "z=1.328488213048321094\n",
    "print(x*y == y*x)  # * commutes\n",
    "print(x+y == y+x)  # + commutes\n",
    "print(x-y == -(y-x)) # - commutes (taking care of sign)\n",
    "print((x+y)+z == x+(y+z)) # + is NOT exactly associative in floating point\n",
    "val1 = (x+y)+z\n",
    "val2 = x+(y+z)\n",
    "relerr = abs(val1-val2)/val1\n",
    "print(\"relative error in associative test\", relerr)\n",
    "print(x*(y+z)==x*y+x*z) # * is NOT exactly distributive in floating point\n",
    "val1 = x*(y+z)\n",
    "val2 = x*y+x*z\n",
    "relerr = abs(val1-val2)/val1\n",
    "print(\"relative error in distributive test\", relerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reliably comparing floating-point values**\n",
    "\n",
    "You must pay attention when comparing two floating point numbers --- since floating computation is imprecise, comparing two numbers should be done allowing for some reasonable error.  But what is reasonable depends on what accuracy you are expecting --- i.e., often you have to decide, but a reasonable default can be obtained from the machine epsilon assuming just rounding error is present.\n",
    "\n",
    "The easiest way to do this is using `math.isclose` (https://docs.python.org/3/whatsnew/3.5.html#pep-485-a-function-for-testing-approximate-equality)\n",
    "\n",
    "*Question:* Why does adding then subtracting 100 lose significance in the value of $\\pi$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 3.552713678800501e-15\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = (math.pi+100.0)-100.0\n",
    "print(x==math.pi, x-math.pi)\n",
    "print(math.isclose(x, math.pi, rel_tol=1e-14)) # *******************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cancellation error:** (loss of significance, https://en.wikipedia.org/wiki/Loss_of_significance) is a more pernicious problem.  \n",
    "\n",
    "Adding/subtracting numbers of similar magnitude to obtain a relatively small result or intermediate value can lose significant digits, sometimes catastrophically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1234567890123456\n",
      "0.1234567890123\n",
      "4.558853294867049e-14\n",
      "1.0\n",
      "0.0\n",
      "3.141592651605606 3.141592653589793\n",
      "-1.984187036896401e-09\n"
     ]
    }
   ],
   "source": [
    "x = 0.1234567890123456\n",
    "y = 0.1234567890123\n",
    "print(x)\n",
    "print(y)\n",
    "print(x-y)\n",
    "print((1.0+2.0**52)-2.0**52)\n",
    "print((1.0+2.0**53)-2.0**53)\n",
    "print((math.pi+1e8)-1e8, math.pi) \n",
    "print((math.pi+1e8)-1e8 - math.pi) # subtract too close will have different float accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Summing data with varying magnitude and sign.\n",
    "\n",
    "Below we first define a function to make a random value that has a large variation in magnitude but is always positive.  Each value is exactly represented as a floating point number since each is just a power of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.891335790108483e-06\n",
      "10.988759697774913\n",
      "490936075.574317\n",
      "1770824207126.2043\n",
      "0.00010067982297399\n",
      "0.06723608469531125\n",
      "3.69988792321518e-05\n",
      "3.116155173360896e-10\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "def ranval():\n",
    "    return 2.0**((random()-0.5)*100)\n",
    "\n",
    "# Print a few out to see what they look like\n",
    "for i in range(8):\n",
    "    print(ranval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sum a list of 1000 such values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum in original order:    1.7683343012977808e+16\n"
     ]
    }
   ],
   "source": [
    "values=[ranval() for i in range(1000)]\n",
    "print(\"sum in original order:   \", sum(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is there rounding error when computing the sum?\n",
    "\n",
    "**Question:** Is cancellation error a concern here?\n",
    "\n",
    "**Question:** Should the order of summation greatly affect the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum in reverse order:    1.7683343012977806e+16\n",
      "sum in sorted order:     1.7683343012977822e+16\n"
     ]
    }
   ],
   "source": [
    "values.reverse()\n",
    "print(\"sum in reverse order:   \", sum(values))\n",
    "print(\"sum in sorted order:    \", sum(sorted(values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that any variation in the relative error is consistent with machine epsilon --- it is just rounding error.\n",
    "\n",
    "\n",
    "Next we make a list of 2000 elements --- the first 1000 are random values computed with the first function and the second 1000 are just the negative of the first.\n",
    "\n",
    "So we know the exact sum should be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=[ranval() for i in range(1000)]\n",
    "values = values + [-value for value in values]\n",
    "print(\"sum in original order:   \", sum(values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is cancellation error a concern here?\n",
    "\n",
    "**Question:** Why should the order of summation matter?\n",
    "\n",
    "**Question:** How can we get the computer to give us the \"correct\" answer?\n",
    "\n",
    "**Question:** In general, if we don't know the \"exact\" result, what do we even mean by \"correct?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sum in original order:  \", sum(values))\n",
    "values.reverse()\n",
    "print(\"sum in reverse order:   \", sum(values))\n",
    "print(\"sum in sorted order:    \", sum(sorted(values)))\n",
    "print(\"sum in abs sorted order:\", sum(sorted(values,key=abs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general even summing sorted data will still have some rounding error and may not even be the optimal algorithm --- we only get zero error here because of this special test case.\n",
    "\n",
    "If you are concerned about the accuracy of a sum of floating point values, you could try using the `math.fsum` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.fsum(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the quadratic equation\n",
    "\n",
    "A classic example for numerical woes is the standard expression for the roots of a quadratic equation\n",
    "\n",
    "$ a x^2 + b x + c = 0$\n",
    "\n",
    "$ x = \\frac{-b \\pm \\sqrt{b^2 - 4 a c}}{2 a}$\n",
    "\n",
    "Three aspects of numerical computation conspire to make problems for this simple formula when $|ac| \\ll b^2$:\n",
    "*  Rounding error when computing $b^2 - 4 a c$\n",
    "*  Cancellation error when computing $-b \\pm \\sqrt{b^2 - 4 a c}$ if $|4ac|\\ll b^2$.\n",
    "\n",
    "Consider adding two numbers $p+q$.  We've already seen that if $q$ is small compared to $p$ the addition operation must discard some of the digits in $q$. In the worst cast, if $|q|<\\epsilon |p|$ then $p+q=p$ in floating-point arithmetic (where $\\epsilon$ is the machine epsilon).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=1.0\n",
    "q=1.2345678901234567e-12\n",
    "print(p,q,p+q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to the quadratic equation problem, imagine that $|ac| < \\epsilon b^2$.\n",
    "* The floating-point value for $b^2 - 4 a c$ will be computed as $b^2$ --- can you explain why?\n",
    "* As a result (and assuming that $b>0$) we will compute $-b + \\sqrt{b^2 - 4 a c}$ to have the value zero (give or take a bit of rounding error). This is the catastrophic cancellation error --- we have lost all information.\n",
    "* Again assuming $|ac| \\ll b^2$, a little bit of math (Taylor series) tells us that the correct answer is  $-b + \\sqrt{b^2 - 4 a c} \\approx + 2 ac/b$ and so that the corresponding root is $x \\approx c/b$\n",
    "* Similar problems arise for the other root if $b<0$.\n",
    "\n",
    "These errors can be avoided by taking advantage of the alternative formula \n",
    "\n",
    "$$x = \\frac{2c}{-b \\mp \\sqrt{b^2 - 4 a c}}$$\n",
    "\n",
    "with '-' when $b\\ge 0$ and '+' when $b<0$.\n",
    "\n",
    "The original and alternative algorithms are implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roots1: (1971.6058, 0.05078649)\n",
      "roots2: (1970.9927, 0.050770696)\n",
      "accurate:  (1971.605915932872, 0.050770693874568965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_29548/4197972976.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def roots1(a,b,c, dtype=np.float):\n",
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_29548/4197972976.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def roots2(a,b,c, dtype=np.float):\n",
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_29548/4197972976.py:16: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  print(\"accurate: \", roots1(a,b,c, np.float))\n"
     ]
    }
   ],
   "source": [
    "def roots1(a,b,c, dtype=np.float):\n",
    "    r = np.sqrt(b**dtype(2) - dtype(4)*a*c)\n",
    "    return (-b+r)/(dtype(2)*a), (-b-r)/(dtype(2)*a)\n",
    "\n",
    "def roots2(a,b,c, dtype=np.float):\n",
    "    r = np.sqrt(b**dtype(2) - dtype(4)*a*c)\n",
    "    return dtype(2)*c/(-b-r), dtype(2)*c/(-b+r)\n",
    "\n",
    "#\n",
    "dtype = np.float32\n",
    "a, b, c = 0.05010, -98.78, 5.015\n",
    "\n",
    "print(\"roots1:\", roots1(dtype(a),dtype(b),dtype(c), dtype))\n",
    "print(\"roots2:\", roots2(dtype(a),dtype(b),dtype(c), dtype))\n",
    "\n",
    "print(\"accurate: \", roots1(a,b,c, np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the two formulas as follws:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hybrid:  (1971.605915932872, 0.050770693874611875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_29548/542171486.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def roots_hybrid(a,b,c, dtype=np.float):\n"
     ]
    }
   ],
   "source": [
    "def roots_hybrid(a,b,c, dtype=np.float):\n",
    "    r = np.sqrt(b**dtype(2) - dtype(4)*a*c)\n",
    "    x1 = (-b+r)/(dtype(2)*a) if b<0 else dtype(2)*c/(-b-r)\n",
    "    x2 = (-b-r)/(dtype(2)*a) if b>0 else dtype(2)*c/(-b+r)\n",
    "    return x1, x2\n",
    "\n",
    "print(\"hybrid: \", roots_hybrid(a,b,c, np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extended and arbitrary precision:** \n",
    "* NumPy supports the \"extended precision\" (typically 80 bit represented as 128 bits) `longfloat` (or `longdouble`). Older version of NumPy used to call `longdouble` as \"`float128`\", which was a misnomer and has been removed.\n",
    "* Some libraries and packages (e.g., Maple or Mathematica) can provide greater (varialbe or arbitrary) precision at the cost of a loss of speed. For Python, the module `mpmath` (http://mpmath.org/) provides arbitrary precision arithmetic and we use this a bit further below.\n",
    "\n",
    "With arbitrary-precision arithmetic, we can use more bits in the mantissa and have arbitrarily large exponents --- but the price is a significant loss of speed.  Also, it is not a magical solution, especially if there is only finite precision or accuracy in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extended_precision roots1:  (1971.605915932872, 0.050770693874568965)\n",
      "extended_precision roots2:  (1971.6059159345382, 0.050770693874611875)\n",
      "extended_precision hybrid:  (1971.605915932872, 0.050770693874611875)\n",
      "108-bit precision roots1:  (mpf('1971.6059159328719689255188750410376'), mpf('0.050770693874611872353338345755832257'))\n",
      "108-bit precision roots2:  (mpf('1971.6059159328719689255188750179019'), mpf('0.050770693874611872353338345755236374'))\n",
      "108-bit precision hybrid:  (mpf('1971.6059159328719689255188750410376'), mpf('0.050770693874611872353338345755236374'))\n"
     ]
    }
   ],
   "source": [
    "a, b, c = 0.05010, -98.78, 5.015\n",
    "\n",
    "dtype = np.longfloat\n",
    "print(\"extended_precision roots1: \", roots1(dtype(a),dtype(b),dtype(c), dtype))\n",
    "print(\"extended_precision roots2: \", roots2(dtype(a),dtype(b),dtype(c), dtype))\n",
    "print(\"extended_precision hybrid: \", roots_hybrid(dtype(a),dtype(b),dtype(c), dtype))\n",
    "\n",
    "import mpmath as mp\n",
    "saveprec, mp.mp.prec = mp.mp.prec, 108 # set precision to 108 bits\n",
    "dtype = mp.mpf\n",
    "\n",
    "print(\"108-bit precision roots1: \", roots1(dtype(a),dtype(b),dtype(c), dtype))\n",
    "print(\"108-bit precision roots2: \", roots2(dtype(a),dtype(b),dtype(c), dtype))\n",
    "print(\"108-bit precision hybrid: \", roots_hybrid(dtype(a),dtype(b),dtype(c), dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
